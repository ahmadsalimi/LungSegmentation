{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaskDiscriminator",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPH42h+FmM0mcVH/TyF0RZU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FFE1TV6sClT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy import ndimage"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISEfRC-lDT_k"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, batch_norm=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm3d(in_channels) if batch_norm else None\n",
        "\n",
        "        self.conv = nn.Sequential(                                                          # B I   H   L   W\n",
        "            nn.Conv3d(in_channels, out_channels, 3, 1, padding=1),                          # B O   H   L   W\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, (3, 2, 2), (1, 2, 2), padding=(1, 0, 0)), # B O   H   L/2 W/2\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout3d(0.2, inplace=True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x     B   I   H   L   W\n",
        "\n",
        "        x = self.batch_norm(x) if self.batch_norm else x    # B I   H   L   W\n",
        "        out = self.conv(x)                                  # B O   H   L/2 W/2\n",
        "\n",
        "        return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm7heaI_Umyv"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels, batch_norms=(False, True)):\n",
        "        super().__init__()\n",
        "\n",
        "        if len(channels) != 3:\n",
        "            raise Exception('You should pass 3 channels as in, hidden and out channels')\n",
        "\n",
        "        if len(batch_norms) != 2:\n",
        "            raise Exception('You should pass 2 batch_norms for 2 basic layers')\n",
        "\n",
        "        self.conv = nn.Sequential(                                  # B I   H   L   W\n",
        "            BasicBlock(channels[0], channels[1], batch_norms[0]),   # B M   H   L/2 W/2\n",
        "            BasicBlock(channels[1], channels[2], batch_norms[1]),   # B O   H   L/4 W/4\n",
        "        )\n",
        "\n",
        "        self.downsample = nn.Sequential(                            # B I   H   L   W\n",
        "            nn.Conv3d(channels[0], channels[2], 3, 1, padding=1),   # B O   H   L   W\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.AvgPool3d((3, 4, 4), (1, 4, 4), padding=(1, 0, 0)),  # B O   H   L/4 W/4\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x     B   I   H   L   W\n",
        "\n",
        "        out = self.conv(x)                  # B O   H   L/4 W/4\n",
        "        downsampled = self.downsample(x)    # B O   H   L/4 W/4\n",
        "\n",
        "        out += downsampled                  # B O   H   L/4 W/4\n",
        "\n",
        "        return out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU2sONg5AuIC"
      },
      "source": [
        "class MaskDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(                          # B 2   H   64  64\n",
        "            ResidualBlock((2, 4, 8), (False, True)),        # B 8   H   16  16\n",
        "            ResidualBlock((8, 16, 32), (False, True)),      # B 32  H   4   4\n",
        "            ResidualBlock((32, 64, 128), (False, True)),    # B 128 H   1   1\n",
        "        )\n",
        "\n",
        "        # H B   128\n",
        "        self.lstm = nn.LSTM(128, 128, num_layers=2)         # 2 B   128 + 2 B   128 =>  B   512\n",
        "\n",
        "        self.decider = nn.Sequential(                       # B 512\n",
        "            nn.Linear(512, 256),                            # B 256\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5, inplace=True),\n",
        "            nn.Linear(256, 128),                            # B 128\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5, inplace=True),\n",
        "            nn.Linear(128, 1),                              # B 1\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x     B   2   H   64  64\n",
        "\n",
        "        x = self.conv(x)                # B 128 H   1   1\n",
        "        x = x.squeeze()                 # B 128 H\n",
        "        x = x.permute(2, 0, 1)          # H B   128\n",
        "        _, (h, c) = self.lstm(x)        # 2 B   128 + 2 B   128\n",
        "        out = torch.cat((h, c))         # 4 B   128\n",
        "        out = out.permute(1, 0, 2)      # B 4   128\n",
        "        out = out.reshape(-1, 512)      # B 512\n",
        "        out = self.decider(out)         # B 1\n",
        "        out = out.squeeze()             # B\n",
        "\n",
        "        return out"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czzqdq0J2Oh1"
      },
      "source": [
        "def get_batches(X, y=None, batch_size=128, shuffle=True):\n",
        "    if y is not None:\n",
        "        assert X.shape[0] == y.shape[0]\n",
        "\n",
        "    num_batches = int(np.ceil(X.shape[0] * 1.0 / batch_size))\n",
        "\n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(X.shape[0])\n",
        "        X = X[indices]\n",
        "        if y is not None:\n",
        "            y = y[indices]\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        start = batch * batch_size\n",
        "        end = min((batch + 1) * batch_size, X.shape[0])\n",
        "        yield (batch, X[start:end], y[start:end]) if y is not None else (batch, X[start:end])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5ekcmeZ2BEv"
      },
      "source": [
        "def train_discriminator(model, optimizer, X, y, batch_size):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for iter, b_X, b_y in get_batches(X, y, batch_size=batch_size):\n",
        "        # b_X   B   2   H   64  64\n",
        "        # b_y   B\n",
        "        images = torch.tensor(b_X, device='cuda')\n",
        "        target = torch.tensor(b_y, device='cuda')\n",
        "\n",
        "        prediction = model(images)\n",
        "\n",
        "        loss = F.binary_cross_entropy(prediction, target)\n",
        "\n",
        "        epoch_loss += float(loss)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if (iter + 1) % 2 == 0:\n",
        "            print(f'[Train] Iteration {iter + 1:3d} - loss: {epoch_loss / (iter + 1):.2e}')\n",
        "\n",
        "    epoch_loss /= iter + 1\n",
        "    return epoch_loss"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V92fpOa6OHy"
      },
      "source": [
        "def evaluate_discriminator(model, X, y, batch_size):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for iter, b_X in get_batches(X, y, batch_size=batch_size, shuffle=False):\n",
        "            images = torch.tensor(b_X, device='cuda')\n",
        "            target = torch.tensor(b_y, device='cuda')\n",
        "\n",
        "            prediction = model(images)\n",
        "\n",
        "            loss = F.binary_cross_entropy(prediction, target)\n",
        "\n",
        "            epoch_loss += float(loss)\n",
        "\n",
        "            if (iter + 1) % 2 == 0:\n",
        "                print(f'[Valid] Iteration {iter + 1:3d} - loss: {epoch_loss / (iter + 1):.2e}')\n",
        "        \n",
        "    epoch_loss /= iter + 1\n",
        "    return epoch_loss"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6O4JI066zE6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}